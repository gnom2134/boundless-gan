{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SnxDaQ1IDqjO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/mikhaillebedev/anaconda3/envs/my-rdkit-env2/lib/python3.9/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: latest is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import elu, instance_norm\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim, utils\n",
    "\n",
    "from torchvision.datasets import Places365\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8CsJ3nfMVwpc"
   },
   "outputs": [],
   "source": [
    "LAMBDA_ADV = 1e-2\n",
    "LR_G = 1e-4\n",
    "LR_D = 1e-3\n",
    "B1 = 0.5\n",
    "B2 = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCWJvVxzSmti"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fTjnERlHGTeb"
   },
   "outputs": [],
   "source": [
    "class SkipConnection(nn.Module):\n",
    "    def forward(self, out, old_out):\n",
    "        return torch.cat([out, old_out], dim=1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class GatedConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True,):\n",
    "        super(GatedConv, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels, \n",
    "                                out_channels, \n",
    "                                kernel_size, \n",
    "                                stride, \n",
    "                                padding, \n",
    "                                dilation, \n",
    "                                groups, \n",
    "                                bias)\n",
    "        self.mask_conv2d = nn.Conv2d(in_channels, \n",
    "                                     out_channels, \n",
    "                                     kernel_size, \n",
    "                                     stride, \n",
    "                                     padding, \n",
    "                                     dilation, \n",
    "                                     groups,\n",
    "                                     bias)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def gated(self, mask):\n",
    "        return self.sigmoid(mask)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.conv2d(inp)\n",
    "        mask = self.mask_conv2d(inp)\n",
    "        x = elu(x) * self.gated(mask)\n",
    "        x = instance_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-rPOSvikEVUJ"
   },
   "outputs": [],
   "source": [
    "class Generator(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.skip = SkipConnection()\n",
    "        self.upsampling = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        self.cache_GC_1 = GatedConv(4, 32, 5, 1, 2)\n",
    "        self.cache_GC_2 = GatedConv(32, 64, 3, 2, 1)\n",
    "        self.cache_GC_3 = GatedConv(64, 64, 3, 1, 1)\n",
    "        self.cache_GC_4 = GatedConv(64, 128, 3, 2, 1)\n",
    "        self.cache_GC_5 = GatedConv(128, 128, 3, 1, 1)\n",
    "\n",
    "        self.mid_pile = nn.Sequential(\n",
    "            GatedConv(128, 128, 3, 1, 1),\n",
    "            GatedConv(128, 128, 3, 1, 2, dilation=2),\n",
    "            GatedConv(128, 128, 3, 1, 4, dilation=4),\n",
    "            GatedConv(128, 128, 3, 1, 8, dilation=8), \n",
    "            GatedConv(128, 128, 3, 1, 16, dilation=16),\n",
    "            GatedConv(128, 128, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.GC_1 = GatedConv(256, 128, 3, 1, 1)\n",
    "        self.GC_2 = GatedConv(256, 64, 3, 1, 1)\n",
    "        self.GC_3 = GatedConv(128, 64, 3, 1, 1)\n",
    "        self.GC_4 = GatedConv(128, 32, 3, 1, 1)\n",
    "        self.GC_5 = GatedConv(64, 16, 3, 1, 1)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(16, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.cache_GC_1(x)\n",
    "        out2 = self.cache_GC_2(out1)\n",
    "        out3 = self.cache_GC_3(out2)\n",
    "        out4 = self.cache_GC_4(out3)\n",
    "        out5 = self.cache_GC_5(out4)\n",
    "\n",
    "        out = self.mid_pile(out5)\n",
    "\n",
    "        out = self.skip(out, out5)\n",
    "        out = self.GC_1(out)\n",
    "\n",
    "        out = self.skip(out, out4)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.GC_2(out)\n",
    "\n",
    "        out = self.skip(out, out3)\n",
    "        out = self.GC_3(out)\n",
    "\n",
    "        out = self.skip(out, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.GC_4(out)\n",
    "\n",
    "        out = self.skip(out, out1)\n",
    "        out = self.GC_5(out)\n",
    "        \n",
    "        out = self.final_conv(out)\n",
    "        return out\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gfxpG5fgK68a"
   },
   "outputs": [],
   "source": [
    "class Discriminator(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = 4, 64\n",
    "        for i in range(6):\n",
    "            layers.append(nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=2, padding=2)))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "            in_channels = out_channels\n",
    "            out_channels = 2 * out_channels if out_channels < 256 else out_channels\n",
    "        layers.append(nn.utils.spectral_norm(nn.Conv2d(256, 256, kernel_size=4, stride=1, padding=0)))\n",
    "        layers.append(nn.LeakyReLU())\n",
    "\n",
    "        self.pile = nn.Sequential(*layers)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.cond_linear = nn.utils.spectral_norm(nn.Linear(1000, 256, bias=False))\n",
    "        self.final_linear = nn.utils.spectral_norm(nn.Linear(256, 1, bias=False))\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        out = torch.cat([x, y], dim=1)\n",
    "        out = self.pile(out)\n",
    "        out = self.flatten(out)\n",
    "        out_t = self.final_linear(out)\n",
    "\n",
    "        z = self.cond_linear(z)\n",
    "        out = (out * z).sum(1, keepdim=True)\n",
    "        out = torch.add(out, out_t)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8KV7gCRCRH18"
   },
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def generator_step(self, input_tensor, real_image, masked_image, mask, cond):\n",
    "\n",
    "        gen_image = self.generator(input_tensor)\n",
    "        loss_rec = torch.nn.L1Loss()(gen_image, real_image)\n",
    "\n",
    "        substituted_gen_image = gen_image * mask + masked_image\n",
    "        loss_adv = -self.discriminator(substituted_gen_image, mask, cond).mean()\n",
    "\n",
    "        loss_G = LAMBDA_ADV * loss_adv + loss_rec\n",
    "\n",
    "        return {\n",
    "            'loss_G': loss_G,\n",
    "            \"loss_adv\": loss_adv,\n",
    "            'loss_rec':  loss_rec\n",
    "        }\n",
    "\n",
    "    def discriminator_step(self, real_image, fake_image, mask, cond):\n",
    "        pred_real = self.discriminator(real_image, mask, cond)\n",
    "        pred_fake = self.discriminator(fake_image.detach(), mask, cond)\n",
    "        loss_D = nn.ReLU()(1.0 - pred_real).mean() + nn.ReLU()(1.0 + pred_fake).mean()\n",
    "\n",
    "        return {\n",
    "            'loss_D': loss_D\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        optimizer_g, optimizer_d = self.optimizers()\n",
    "\n",
    "        input_tensor = torch.Tensor(batch[\"input_tensor\"]).to(torch.float32)\n",
    "        cond = torch.Tensor(batch[\"inception_embeds\"])\n",
    "        \n",
    "        real_image = input_tensor[:, :3, :, :]\n",
    "        mask = input_tensor[:, 3:, :, :]\n",
    "        masked_image = mask * real_image\n",
    "\n",
    "        \n",
    "        self.toggle_optimizer(optimizer_g, 0)\n",
    "\n",
    "        G_output = self.generator_step(input_tensor, real_image, masked_image, mask, cond)\n",
    "        loss_g =  G_output['loss_G']\n",
    "        self.log('Generator loss', loss_g)\n",
    "        self.manual_backward(loss_g)\n",
    "        optimizer_g.step()\n",
    "        optimizer_g.zero_grad()\n",
    "        self.untoggle_optimizer(optimizer_g)\n",
    "\n",
    "\n",
    "        self.toggle_optimizer(optimizer_d, 1)\n",
    "\n",
    "        gen_image = self.generator(input_tensor)\n",
    "        fake_image = gen_image * mask + masked_image\n",
    "\n",
    "        D_output = self.discriminator_step(real_image, fake_image, mask, cond)\n",
    "        loss_d =  D_output['loss_D']\n",
    "        self.log('Discriminator loss', loss_d)\n",
    "        self.manual_backward(loss_d)\n",
    "        optimizer_d.step()\n",
    "        optimizer_d.zero_grad()\n",
    "        self.untoggle_optimizer(optimizer_d)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=LR_G, betas=(B1, B2))\n",
    "        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=LR_D, betas=(B1, B2))\n",
    "        return [optimizer_G, optimizer_D], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dWUiANLFrgfH"
   },
   "outputs": [],
   "source": [
    "boundless_gan = GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeTpaoHjRqvW"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cEP1JjoQUvcZ"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.places365 import Places365\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "class ExampleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.rand((3, 256, 256))\n",
    "        self.mask = torch.ones((256, 256))\n",
    "        self.mask = self.mask[None, :, :]\n",
    "\n",
    "        self.input_tensor = torch.cat([self.data, self.mask])\n",
    "        self.inception_embeds = torch.zeros((1000))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"input_tensor\": self.input_tensor,\n",
    "            \"inception_embeds\": self.inception_embeds,\n",
    "        }\n",
    "\n",
    "\n",
    "class Places365Embedding(Places365):\n",
    "    def __init__(self, embeddings_path: Path, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.embeddings = torch.from_numpy(np.load(str(embeddings_path)))\n",
    "\n",
    "    #         self.transform = transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, _ = super(Places365Embedding, self).__getitem__(item)\n",
    "        print(img.shape)\n",
    "        embedding = self.embeddings[item, :]\n",
    "        return {\"input_tensor\": img, \"inception_embeds\": embedding}\n",
    "\n",
    "\n",
    "def add_mask(image, mask_percentage, inpainting=False):\n",
    "    \"\"\"Add a mask to an image.\n",
    "    Args:\n",
    "        image (PIL.Image): Image to add the mask to.\n",
    "        mask_percentage (float): Percentage of the image to mask.\n",
    "        inpainting (bool): If True, the mask will be a square in the center of the image.\n",
    "    Returns:\n",
    "            torch.Tensor: Image with the mask.\"\"\"\n",
    "    image = F.pil_to_tensor(image)\n",
    "    num_channels, height, width = image.shape\n",
    "    mask = torch.ones((height, width), dtype=torch.bool)\n",
    "    mask_width = int(width * mask_percentage)\n",
    "    random_delta = np.random.randint(-4, 5)\n",
    "    if inpainting:\n",
    "        mask_size = int(np.sqrt(np.prod(image.shape[1:]) * mask_percentage))\n",
    "        start_h = (image.shape[1] - mask_size) // 2\n",
    "        start_w = (image.shape[2] - mask_size) // 2\n",
    "        mask[start_h : start_h + mask_size, start_w : start_w + mask_size] = 0\n",
    "    else:\n",
    "        mask_width = mask_width + random_delta\n",
    "        mask[:, width - mask_width :] = 0\n",
    "    return torch.cat([image, mask.reshape(1, height, width)], dim=0)\n",
    "\n",
    "\n",
    "# Usage example\n",
    "# places365_dataset = torchvision.datasets.Places365(\n",
    "#     \"./data/pt_dataset/\",\n",
    "#     small=True,\n",
    "#     download=False,\n",
    "#     transform=partial(add_mask, mask_percentage=0.25, inpainting=False),\n",
    "# )\n",
    "\n",
    "places365_dataset = Places365Embedding(\n",
    "    root=\"../data/pt_dataset/\",\n",
    "    small=True,\n",
    "    download=False,\n",
    "    transform=partial(add_mask, mask_percentage=0.25, inpainting=False),\n",
    "    embeddings_path=\"../embeddings_inceptionv3_places365.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_YwcNneJuFSu"
   },
   "outputs": [],
   "source": [
    "# dataset = ExampleDataset()\n",
    "train_loader = utils.data.DataLoader(places365_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "{'input_tensor': tensor([[[[187, 187, 187,  ..., 173, 172, 172],\n",
      "          [187, 187, 188,  ..., 173, 172, 172],\n",
      "          [187, 188, 188,  ..., 173, 173, 172],\n",
      "          ...,\n",
      "          [187, 188, 188,  ..., 175, 174, 174],\n",
      "          [187, 187, 188,  ..., 175, 174, 174],\n",
      "          [187, 187, 187,  ..., 175, 174, 174]],\n",
      "\n",
      "         [[188, 188, 188,  ..., 174, 173, 173],\n",
      "          [188, 188, 189,  ..., 174, 173, 173],\n",
      "          [188, 189, 189,  ..., 174, 174, 173],\n",
      "          ...,\n",
      "          [189, 190, 190,  ..., 179, 178, 178],\n",
      "          [189, 189, 190,  ..., 179, 178, 178],\n",
      "          [189, 189, 189,  ..., 179, 178, 178]],\n",
      "\n",
      "         [[190, 190, 190,  ..., 178, 177, 177],\n",
      "          [190, 190, 191,  ..., 178, 177, 177],\n",
      "          [190, 191, 191,  ..., 178, 178, 177],\n",
      "          ...,\n",
      "          [202, 203, 203,  ..., 191, 190, 190],\n",
      "          [202, 202, 203,  ..., 191, 190, 190],\n",
      "          [202, 202, 202,  ..., 191, 190, 190]],\n",
      "\n",
      "         [[  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0]]],\n",
      "\n",
      "\n",
      "        [[[240, 240, 241,  ..., 231, 231, 231],\n",
      "          [239, 240, 240,  ..., 231, 231, 231],\n",
      "          [238, 239, 239,  ..., 231, 231, 231],\n",
      "          ...,\n",
      "          [154, 154, 154,  ..., 157, 154, 150],\n",
      "          [153, 150, 148,  ..., 158, 155, 151],\n",
      "          [157, 152, 148,  ..., 159, 156, 153]],\n",
      "\n",
      "         [[243, 243, 244,  ..., 234, 234, 234],\n",
      "          [242, 243, 243,  ..., 234, 234, 234],\n",
      "          [241, 242, 242,  ..., 234, 234, 234],\n",
      "          ...,\n",
      "          [134, 134, 134,  ..., 137, 134, 130],\n",
      "          [133, 130, 128,  ..., 138, 135, 131],\n",
      "          [137, 132, 128,  ..., 139, 136, 133]],\n",
      "\n",
      "         [[250, 250, 251,  ..., 243, 243, 243],\n",
      "          [249, 250, 250,  ..., 243, 243, 243],\n",
      "          [248, 249, 249,  ..., 243, 243, 243],\n",
      "          ...,\n",
      "          [125, 125, 125,  ..., 126, 123, 119],\n",
      "          [124, 121, 119,  ..., 127, 124, 120],\n",
      "          [128, 123, 119,  ..., 128, 125, 122]],\n",
      "\n",
      "         [[  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0]]],\n",
      "\n",
      "\n",
      "        [[[101, 101, 101,  ..., 107, 107, 107],\n",
      "          [101, 101, 101,  ..., 107, 107, 107],\n",
      "          [101, 101, 101,  ..., 107, 107, 107],\n",
      "          ...,\n",
      "          [202, 202, 202,  ..., 206, 206, 206],\n",
      "          [200, 200, 200,  ..., 206, 206, 206],\n",
      "          [196, 196, 197,  ..., 206, 206, 206]],\n",
      "\n",
      "         [[147, 147, 147,  ..., 153, 153, 153],\n",
      "          [147, 147, 147,  ..., 153, 153, 153],\n",
      "          [147, 147, 147,  ..., 153, 153, 153],\n",
      "          ...,\n",
      "          [200, 200, 200,  ..., 203, 203, 203],\n",
      "          [198, 198, 198,  ..., 203, 203, 203],\n",
      "          [194, 194, 195,  ..., 203, 203, 203]],\n",
      "\n",
      "         [[197, 197, 197,  ..., 203, 203, 203],\n",
      "          [197, 197, 197,  ..., 203, 203, 203],\n",
      "          [197, 197, 197,  ..., 203, 203, 203],\n",
      "          ...,\n",
      "          [188, 188, 188,  ..., 184, 184, 184],\n",
      "          [186, 186, 186,  ..., 184, 184, 184],\n",
      "          [182, 182, 183,  ..., 184, 184, 184]],\n",
      "\n",
      "         [[  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 98,  98,  98,  ...,  93,  93,  93],\n",
      "          [ 98,  98,  99,  ...,  94,  93,  93],\n",
      "          [ 98,  99,  99,  ...,  94,  94,  94],\n",
      "          ...,\n",
      "          [101,  79,  90,  ..., 136, 131, 125],\n",
      "          [ 99,  90,  89,  ..., 137, 133, 129],\n",
      "          [ 96, 105,  90,  ..., 129, 126, 124]],\n",
      "\n",
      "         [[145, 145, 145,  ..., 139, 139, 139],\n",
      "          [145, 145, 146,  ..., 140, 139, 139],\n",
      "          [145, 146, 146,  ..., 140, 140, 140],\n",
      "          ...,\n",
      "          [100,  78,  89,  ..., 123, 118, 112],\n",
      "          [ 98,  89,  88,  ..., 124, 120, 116],\n",
      "          [ 95, 104,  89,  ..., 116, 113, 111]],\n",
      "\n",
      "         [[175, 175, 175,  ..., 172, 172, 172],\n",
      "          [175, 175, 176,  ..., 173, 172, 172],\n",
      "          [175, 176, 176,  ..., 173, 173, 173],\n",
      "          ...,\n",
      "          [ 44,  24,  35,  ...,  79,  74,  70],\n",
      "          [ 41,  33,  32,  ...,  80,  78,  74],\n",
      "          [ 38,  47,  32,  ...,  74,  71,  69]],\n",
      "\n",
      "         [[  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0]]],\n",
      "\n",
      "\n",
      "        [[[132, 131, 130,  ..., 169, 169, 170],\n",
      "          [130, 131, 132,  ..., 169, 169, 170],\n",
      "          [130, 132, 135,  ..., 169, 169, 170],\n",
      "          ...,\n",
      "          [ 61,  51,  62,  ...,  39,  34,  34],\n",
      "          [ 63,  56,  64,  ...,  42,  39,  34],\n",
      "          [ 78,  69,  69,  ...,  50,  51,  43]],\n",
      "\n",
      "         [[178, 177, 176,  ..., 197, 197, 198],\n",
      "          [176, 177, 178,  ..., 197, 197, 198],\n",
      "          [176, 178, 181,  ..., 197, 197, 198],\n",
      "          ...,\n",
      "          [ 81,  71,  81,  ...,  58,  53,  54],\n",
      "          [ 83,  76,  83,  ...,  61,  58,  54],\n",
      "          [ 98,  89,  88,  ...,  69,  70,  62]],\n",
      "\n",
      "         [[228, 227, 226,  ..., 234, 234, 235],\n",
      "          [226, 227, 228,  ..., 234, 234, 235],\n",
      "          [226, 228, 231,  ..., 234, 234, 235],\n",
      "          ...,\n",
      "          [ 22,  12,  25,  ...,  12,   7,   5],\n",
      "          [ 24,  17,  27,  ...,  15,  12,   5],\n",
      "          [ 39,  30,  32,  ...,  23,  24,  16]],\n",
      "\n",
      "         [[  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0]]],\n",
      "\n",
      "\n",
      "        [[[ 45,  45,  45,  ...,   0,   0,   0],\n",
      "          [ 45,  45,  45,  ...,   0,   0,   0],\n",
      "          [ 45,  45,  45,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [ 15,  15,  15,  ...,  61,  86, 121],\n",
      "          [ 15,  16,  17,  ...,  21,  32,  51],\n",
      "          [ 15,  16,  18,  ...,  21,  15,  15]],\n",
      "\n",
      "         [[ 91,  91,  91,  ...,   4,   5,   6],\n",
      "          [ 91,  91,  91,  ...,   4,   4,   5],\n",
      "          [ 91,  91,  91,  ...,   3,   4,   5],\n",
      "          ...,\n",
      "          [ 23,  23,  22,  ...,  62,  87, 122],\n",
      "          [ 23,  24,  25,  ...,  21,  32,  51],\n",
      "          [ 23,  24,  26,  ...,  21,  15,  15]],\n",
      "\n",
      "         [[150, 150, 150,  ...,   0,   0,   0],\n",
      "          [150, 150, 150,  ...,   0,   0,   0],\n",
      "          [150, 150, 150,  ...,   2,   2,   2],\n",
      "          ...,\n",
      "          [ 26,  26,  28,  ...,  56,  81, 114],\n",
      "          [ 26,  27,  28,  ...,  19,  30,  49],\n",
      "          [ 26,  27,  29,  ...,  21,  15,  15]],\n",
      "\n",
      "         [[  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0],\n",
      "          [  1,   1,   1,  ...,   0,   0,   0]]]], dtype=torch.uint8), 'inception_embeds': tensor([[-0.1163,  0.2856,  1.2559,  ..., -0.2044, -0.9781,  0.0988],\n",
      "        [-0.4639, -0.5824,  0.5081,  ..., -0.6920, -0.5362, -1.1855],\n",
      "        [-0.6261,  0.3454,  0.0153,  ..., -0.5021, -0.1802, -0.7059],\n",
      "        ...,\n",
      "        [ 1.2391,  1.8294, -0.5924,  ..., -1.0699,  1.4101, -0.7482],\n",
      "        [ 0.3839, -0.6519, -0.5385,  ..., -0.9214, -0.2678, -0.8463],\n",
      "        [-0.3728, -0.5234,  0.1978,  ...,  0.0700, -0.2774,  0.1048]])}\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451,
     "referenced_widgets": [
      "07bba9a075e244f3b9f628b3c3d1fd01",
      "116e31779a434220968b3378c33ae63e",
      "4fd30f7d55854092b68153d8306a0d5c",
      "1fb4c843733b46338c781ae0c9da1759",
      "59e64a43db4c48a398dcda6c728db516",
      "80fe28379eae4eb989667d26fc3f6d95",
      "0dd8880dcb3247649bb10e1fc4e341cc",
      "ed1418d11c8449c8aee000cab0b48bce",
      "160ad52b34b849e0b181713fdc284c88",
      "08fb41362acb493bbc15bb8e23b07a6a",
      "49498fd9239640d192a5ab0596567b4b"
     ]
    },
    "id": "wUFMtNC0unwH",
    "outputId": "0f1340d8-6b69-4a06-86f5-fb8ff450fa1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 8 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 3.5 M \n",
      "1 | discriminator | Discriminator | 7.3 M \n",
      "------------------------------------------------\n",
      "10.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.7 M    Total params\n",
      "42.834    Total estimated model params size (MB)\n",
      "/data/user/mikhaillebedev/anaconda3/envs/my-rdkit-env2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.6068093776702881,
       "initial": 0,
       "n": 0,
       "ncols": 150,
       "nrows": 47,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b8ead75e9e41088078cc895b844fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/mikhaillebedev/anaconda3/envs/my-rdkit-env2/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=5, accelerator=\"auto\", devices=\"auto\", strategy=\"auto\")\n",
    "trainer.fit(model=boundless_gan, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_a = torch.ones([32, 3, 256, 256])\n",
    "some_a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07bba9a075e244f3b9f628b3c3d1fd01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_116e31779a434220968b3378c33ae63e",
       "IPY_MODEL_4fd30f7d55854092b68153d8306a0d5c",
       "IPY_MODEL_1fb4c843733b46338c781ae0c9da1759"
      ],
      "layout": "IPY_MODEL_59e64a43db4c48a398dcda6c728db516"
     }
    },
    "08fb41362acb493bbc15bb8e23b07a6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dd8880dcb3247649bb10e1fc4e341cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "116e31779a434220968b3378c33ae63e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80fe28379eae4eb989667d26fc3f6d95",
      "placeholder": "​",
      "style": "IPY_MODEL_0dd8880dcb3247649bb10e1fc4e341cc",
      "value": "Epoch 0: 100%"
     }
    },
    "160ad52b34b849e0b181713fdc284c88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1fb4c843733b46338c781ae0c9da1759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08fb41362acb493bbc15bb8e23b07a6a",
      "placeholder": "​",
      "style": "IPY_MODEL_49498fd9239640d192a5ab0596567b4b",
      "value": " 3/3 [00:19&lt;00:00,  6.59s/it, v_num=0]"
     }
    },
    "49498fd9239640d192a5ab0596567b4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fd30f7d55854092b68153d8306a0d5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed1418d11c8449c8aee000cab0b48bce",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_160ad52b34b849e0b181713fdc284c88",
      "value": 3
     }
    },
    "59e64a43db4c48a398dcda6c728db516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "80fe28379eae4eb989667d26fc3f6d95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed1418d11c8449c8aee000cab0b48bce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
